---
layout: post
title: Intellectual Minimalism ⬇️
draft: true
---

## tl;dr

...

## Intro

People get frustrated when they ask me about my opinion about something. *Do you think AI is going to eliminate all software engineering jobs?* *What's your stance on the loosening of immigration policy in Canada?* *Is the dress blue and black, or white and gold?* Most of the time, my answer is, "I don't know" (For the last question, it's white and gold. You're visually impaired otherwise). Actually, I respond with questions. Question that come from the awareness that I'm probably not informed enough to have an opinion. Whether its about speculating on the impact of emerging technologies, current political issues, or a viral cultural debate, I keep my opinions and beliefs to a minimum. 

Between our ears sits a biological neural network with 80-90 billion parameters, a number that's relatively stable for each of us throughout our lives. Connections between neurons are fluid but for the most part, our cognitive capacity is constant. So I curate the information I allow into my network. Naturally, that means I try and minimize the number of opinions I store. To put it conicisely, I have a limited budget for how many fucks I can give, so I try and choose only the fucks that matter most.

With this piece, I'm going to describe the design choices behind my internal belief architecture. It's based on a philosophy of minimalism that has helped me control my information intake, reduce mental clutter, and cultivate focus.

## Utility Principle

This is the principle at the core of my intellectual minimalism: I only form and maintain beliefs that serve a ***pertinent and practical*** purpose in my life or work. I still loosely hang on to facts, advice, external opinions, etc. but each of those live in a quasi-quantum state inside my head, between acceptance and rejection. The wave function collapses to a decision when I must form an opinion as a precursor to action.

Some of the questions I ask myself when I drift into belief formation: *Would this opinion directly impact my actions or decisions? Does it contribute to my personal growth or professional development? Is it essential for my interactions with others or understanding of the world?* If the answer to such questions is "no," I often choose not to form a strong opinion on the matter. This doesn't mean I'm uninformed or uninterested. Rather, I maintain a state of informed neutrality, aware of the key points and arguments but not committing to a stance. For instance, I may not have a strong opinion on the exact timeline of AGI development, but I do invest in understanding its potential impacts on my field of software engineering. 

This principle doesn't advocate for willful ignorance. Instead, it promotes a thoughtful curation of our beliefs, ensuring they are not numerous, but instead, they're meaningful and actionable.

### Pertinent and Practical

So what counts as "pertinent and practical"? It depends on a person's priorities, but the answer for me is, my life priorities. I try to spend my conviction on matters that concern,
* Myself (eg. health, personal safety)
* My family
* My friends
* My partner
* And my communities (consisting of my customers, fellow founders, professional connections, etc.)

I focus my attention to my *zones of influence*. What inhabits these zones can change over time, especially the communities that I consider important, like my professional peers, and customer base. But I try to scope my intellect to realms that align with my goals, and where I can have some tangible influence.

### What about the butterfly over there?

The butterfly effect is a concept in chaos theory. It suggests that small changes somewhere can lead to far-reaching and unpredictable consequences elsewhere. The canonical example is of a butterfly flapping its wings in Brazil, which could theoretically cause a tornado in Texas. When it comes to honing my belief stack, this raises a valid question: *"If everything is potentially connected, shouldn't you form opinions on everything?"*

The whole point of intellectual minimalism is to free up our cognition, and basing our belief system on far-reaching connections can lead to cognitive overload and decision paralysis. So I like to believe (see what I did there), while everything might be connected, our ability to influence or predict these connections diminishes rapidly as we move further from our immediate sphere. I don't ignore broader contexts or systemic thinking. Rather, I focus on the butterflies in my own garden - the immediate causes and effects I can observe, understand, and potentially influence. For instance, while it might be interesting to ponder how warring countries on the other side of the planet could eventually affect my life through some chain of events, it's often more productive to focus on your neighborhood's zoning policies, or issues facing your customers, or the impact of emerging technologies on your business, etc.
